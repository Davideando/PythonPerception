{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Antes de realizar ningún punto, se inicializa todas las funciones que se van a necesitar en todo el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Se importa la librería de numpy\n",
    "import numpy as np\n",
    "# Se importa la función para obtener el valor de \"Least-squares\"\n",
    "from scipy.linalg import lstsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Q1**) Se descarga todo el dataset, y se guarda con el nombre de \"*housing.data*\". \n",
    "\n",
    "- **Q2**) Se cargan los datos y se separa la última columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points:  506\n",
      "[ 24.   21.6  34.7  33.4  36.2  28.7  22.9  27.1  16.5  18.9  15.   18.9\n",
      "  21.7  20.4  18.2  19.9  23.1  17.5  20.2  18.2  13.6  19.6  15.2  14.5\n",
      "  15.6  13.9  16.6  14.8  18.4  21.   12.7  14.5  13.2  13.1  13.5  18.9\n",
      "  20.   21.   24.7  30.8  34.9  26.6  25.3  24.7  21.2  19.3  20.   16.6\n",
      "  14.4  19.4  19.7  20.5  25.   23.4  18.9  35.4  24.7  31.6  23.3  19.6\n",
      "  18.7  16.   22.2  25.   33.   23.5  19.4  22.   17.4  20.9  24.2  21.7\n",
      "  22.8  23.4  24.1  21.4  20.   20.8  21.2  20.3  28.   23.9  24.8  22.9\n",
      "  23.9  26.6  22.5  22.2  23.6  28.7  22.6  22.   22.9  25.   20.6  28.4\n",
      "  21.4  38.7  43.8  33.2  27.5  26.5  18.6  19.3  20.1  19.5  19.5  20.4\n",
      "  19.8  19.4  21.7  22.8  18.8  18.7  18.5  18.3  21.2  19.2  20.4  19.3\n",
      "  22.   20.3  20.5  17.3  18.8  21.4  15.7  16.2  18.   14.3  19.2  19.6\n",
      "  23.   18.4  15.6  18.1  17.4  17.1  13.3  17.8  14.   14.4  13.4  15.6\n",
      "  11.8  13.8  15.6  14.6  17.8  15.4  21.5  19.6  15.3  19.4  17.   15.6\n",
      "  13.1  41.3  24.3  23.3  27.   50.   50.   50.   22.7  25.   50.   23.8\n",
      "  23.8  22.3  17.4  19.1  23.1  23.6  22.6  29.4  23.2  24.6  29.9  37.2\n",
      "  39.8  36.2  37.9  32.5  26.4  29.6  50.   32.   29.8  34.9  37.   30.5\n",
      "  36.4  31.1  29.1  50.   33.3  30.3  34.6  34.9  32.9  24.1  42.3  48.5\n",
      "  50.   22.6  24.4  22.5  24.4  20.   21.7  19.3  22.4  28.1  23.7  25.\n",
      "  23.3  28.7  21.5  23.   26.7  21.7  27.5  30.1  44.8  50.   37.6  31.6\n",
      "  46.7  31.5  24.3  31.7  41.7  48.3  29.   24.   25.1  31.5  23.7  23.3\n",
      "  22.   20.1  22.2  23.7  17.6  18.5  24.3  20.5  24.5  26.2  24.4  24.8\n",
      "  29.6  42.8  21.9  20.9  44.   50.   36.   30.1  33.8  43.1  48.8  31.\n",
      "  36.5  22.8  30.7  50.   43.5  20.7  21.1  25.2  24.4  35.2  32.4  32.\n",
      "  33.2  33.1  29.1  35.1  45.4  35.4  46.   50.   32.2  22.   20.1  23.2\n",
      "  22.3  24.8  28.5  37.3  27.9  23.9  21.7  28.6  27.1  20.3  22.5  29.\n",
      "  24.8  22.   26.4  33.1  36.1  28.4  33.4  28.2  22.8  20.3  16.1  22.1\n",
      "  19.4  21.6  23.8  16.2  17.8  19.8  23.1  21.   23.8  23.1  20.4  18.5\n",
      "  25.   24.6  23.   22.2  19.3  22.6  19.8  17.1  19.4  22.2  20.7  21.1\n",
      "  19.5  18.5  20.6  19.   18.7  32.7  16.5  23.9  31.2  17.5  17.2  23.1\n",
      "  24.5  26.6  22.9  24.1  18.6  30.1  18.2  20.6  17.8  21.7  22.7  22.6\n",
      "  25.   19.9  20.8  16.8  21.9  27.5  21.9  23.1  50.   50.   50.   50.\n",
      "  50.   13.8  13.8  15.   13.9  13.3  13.1  10.2  10.4  10.9  11.3  12.3\n",
      "   8.8   7.2  10.5   7.4  10.2  11.5  15.1  23.2   9.7  13.8  12.7  13.1\n",
      "  12.5   8.5   5.    6.3   5.6   7.2  12.1   8.3   8.5   5.   11.9  27.9\n",
      "  17.2  27.5  15.   17.2  17.9  16.3   7.    7.2   7.5  10.4   8.8   8.4\n",
      "  16.7  14.2  20.8  13.4  11.7   8.3  10.2  10.9  11.    9.5  14.5  14.1\n",
      "  16.1  14.3  11.7  13.4   9.6   8.7   8.4  12.8  10.5  17.1  18.4  15.4\n",
      "  10.8  11.8  14.9  12.6  14.1  13.   13.4  15.2  16.1  17.8  14.9  14.1\n",
      "  12.7  13.5  14.9  20.   16.4  17.7  19.5  20.2  21.4  19.9  19.   19.1\n",
      "  19.1  20.1  19.9  19.6  23.2  29.8  13.8  13.3  16.7  12.   14.6  21.4\n",
      "  23.   23.7  25.   21.8  20.6  21.2  19.1  20.6  15.2   7.    8.1  13.6\n",
      "  20.1  21.8  24.5  23.1  19.7  18.3  21.2  17.5  16.8  22.4  20.6  23.9\n",
      "  22.   11.9]\n"
     ]
    }
   ],
   "source": [
    "# Se abre el fichero de datos\n",
    "data = np.loadtxt(\"housing.data\")\n",
    "# Se separa la última fila, que contendrá los valores correctos\n",
    "target = data[:,-1]\n",
    "print 'Total data points: ', len(target)\n",
    "print target.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos preparados, se debe encontrar la media de los resultados, y despues encontrar el MSE utilizando una prediccion constante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La media es 22.5328063241\n"
     ]
    }
   ],
   "source": [
    "# Se calcula la media de los datos de salida\n",
    "mean_value = sum(target)/len(target)\n",
    "print 'La media es', mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Para calcular Theta, se definen unos comandos para reducir los comandos \n",
    "# que se obtienen desde la librería numpy\n",
    "dot = np.dot\n",
    "inv = np.linalg.inv\n",
    "\n",
    "# Se inicializa toda la variable de X con unos.\n",
    "X = np.ones((len(data),1))\n",
    "\n",
    "# Utilizando estos valores, se calcula Theta utilizando la formula:\n",
    "# Theta = (X^T*X)^-1 * X^T*y\n",
    "# sustituyendo queda\n",
    "\n",
    "Theta = dot(inv(dot(X.T,X)),dot(X.T,target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular el MSE se va a definir una función que realizará el calculo, porque durante el ejercicio se va a utilizar muchas veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado Q2) El MSE es  84.4195561562\n"
     ]
    }
   ],
   "source": [
    "# Función para calcular el MSE\n",
    "# La formula para calcula el MSE es:\n",
    "# MSE = sum(y - X*Theta)²/N\n",
    "def MSE(Y,X,THETA):\n",
    "    MSE = sum((Y-dot(X,THETA))**2) / len(Y)\n",
    "    return MSE\n",
    "\n",
    "# Se calcula el MSE\n",
    "MSE_Q2 = MSE(target,X, Theta)\n",
    "\n",
    "print 'Resultado Q2) El MSE es ', MSE_Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- **Q3**) Hay que dividir los datos por la mitad, la mitad superior será para entrenamiento, y la parte inferior para testear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Se dividen los datos en dos partes\n",
    "\n",
    "# Primero se crean los indices de los dos margenes de valores\n",
    "Train_Rows = len(data)/2\n",
    "Test_Rows = len(data) - Train_Rows\n",
    "\n",
    "# Ahora se dividen los datos en dos partes, entrenamiento y test\n",
    "Train_data = data[:Train_Rows,:-1]\n",
    "Test_data = data[Test_Rows:,:-1]\n",
    "\n",
    "#Por último se dividen los resultados en dos grupos\n",
    "Train_result = data[:Train_Rows,-1]\n",
    "Test_result = data[Test_Rows:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es generar entrenar el *Linear regression* para cada una de las columnas del *data set*, con el termino de bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3.- Los resultados del MSE con los datos de entrenamiento es:\n",
      "\n",
      "[65.773395404381432, 62.184864129384579, 60.202946298313769, 69.24037546862543, 61.545279056417812, 15.93514792057165, 61.427495917253601, 68.000623079838476, 69.14935937656351, 65.435881603038396, 59.750972582605677, 66.040752768311776, 34.380755775897235]\n",
      "\n",
      "Q3.- Los resultados del MSE con los datos de test es:\n",
      "\n",
      "[873.51687362382017, 91.933794664840448, 74.746111965988774, 105.20352304376993, 80.160126225464296, 78.055634425305982, 88.955360723285224, 97.463242190867064, 144.9052308496002, 67.517480981725654, 72.507163330551407, 86.449500143875355, 43.34372359529646]\n"
     ]
    }
   ],
   "source": [
    "# Se crea una matriz para guardar los valores del MSE de los \n",
    "# datos de entrenamiento \n",
    "MSE_Train_Result = []\n",
    "\n",
    "# Se crea una matriz para guardar los valores del MSE de los \n",
    "# datos de test\n",
    "MSE_Test_Result = []\n",
    "\n",
    "# Se crea un bucle obtener todos los valores\n",
    "for i in range(0,len(data[0])-1):\n",
    "    # Se añade la columna a los datos de entreno\n",
    "    X_train = np.hstack((X[:Train_Rows],Train_data[:,i].reshape(Train_Rows,1)))\n",
    "    \n",
    "    # Se añaden la columna a los datos de test\n",
    "    X_test = np.hstack((X[Test_Rows:],Test_data[:,i].reshape(Test_Rows,1)))\n",
    "    \n",
    "    # Ahora se obtiene el valor de Theta con los valores de entrenamiento\n",
    "    theta_value = lstsq(X_train,Train_result)[0]\n",
    "    \n",
    "    #Se calcula el MSE para los valores de entrenamiento\n",
    "    MSE_Train_Result.append(MSE(Train_result,X_train,theta_value))\n",
    "    \n",
    "    #Se calcula el MSE para los valores de test\n",
    "    MSE_Test_Result.append(MSE(Test_result,X_test,theta_value))\n",
    "    \n",
    "# Se imprimen los resultados de los MSE\n",
    "print 'Q3.- Los resultados del MSE con los datos de entrenamiento es:\\n'\n",
    "print MSE_Train_Result\n",
    "print '\\nQ3.- Los resultados del MSE con los datos de test es:\\n'\n",
    "print MSE_Test_Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es calcular el valor *most informative* de los valores de entrenamiento, y el mejor y peor valor para los valores de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3.- El valor más informativo es el  5 , con un MSE de  15.9351479206\n",
      "Q3.- El mejor valor es  12 , con un MSE de  43.3437235953\n",
      "Q3.- El peor valor es  0 , con un MSE de  873.516873624\n"
     ]
    }
   ],
   "source": [
    "# Se calcula el indice del valor mínimo de los valores de entrenamiento, que será el valor \n",
    "# más informativo\n",
    "Train_index_min = MSE_Train_Result.index(min(MSE_Train_Result))\n",
    "print 'Q3.- El valor más informativo es el ', Train_index_min,', con un MSE de ', MSE_Train_Result[Train_index_min]\n",
    "\n",
    "# Se calcula el indice del valor mínimo de los valores de test, que será el valor \n",
    "# mejor valor\n",
    "Test_index_min = MSE_Test_Result.index(min(MSE_Test_Result))\n",
    "print 'Q3.- El mejor valor es ', Test_index_min,', con un MSE de ', MSE_Test_Result[Test_index_min]\n",
    "\n",
    "# Se calcula el indice del valor máximo de los valores de test, que será el valor \n",
    "# peor valor\n",
    "Test_index_max = MSE_Test_Result.index(max(MSE_Test_Result))\n",
    "print 'Q3.- El peor valor es ', Test_index_max,', con un MSE de ', MSE_Test_Result[Test_index_max]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, se va debe cacluar el coeficiente de deteminación R² de los valores de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3.- El Coeficiente de determinación R² de los valores de test es  [-8.3637876   0.01450269  0.19874849 -0.12774404  0.1407122   0.16327159\n",
      "  0.04643044 -0.044771   -0.5533321   0.27623682  0.22274921  0.07329236\n",
      "  0.53537083]\n"
     ]
    }
   ],
   "source": [
    "# La formula para calcular R² = 1 - FVU(f), donde FVU(f) = MSE(f)/Var(y),\n",
    "# por tanto, hay que comenzar calculando la media de los valores\n",
    "R2_Mean = sum(Test_result)/Test_Rows\n",
    "\n",
    "# Y contunuar calculando la variancia\n",
    "R2_var = sum((R2_Mean - Test_result)**2)/Test_Rows\n",
    "\n",
    "# Con todo esto ya se puede calcular el valor R²\n",
    "R2 = 1 - (MSE_Test_Result/R2_var)\n",
    "\n",
    "# Se imprime el resultado\n",
    "print 'Q3.- El Coeficiente de determinación R² de los valores de test es ', R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Q4**) Ahora se debe entrenar todo el modelo utilizando todas las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4.- El MSE de los valores de entreno con todos los datos es:  9.98751732546\n",
      "Q4.- El MSE de los valores de test con todos los datos es:  303.436862927\n"
     ]
    }
   ],
   "source": [
    "# Primero se añaden todos los valores y el valor de bias a los valores de entreno\n",
    "X_train_all = np.hstack((X[:Train_Rows],Train_data[:,:].reshape(Train_Rows,len(Train_data[0]))))\n",
    "\n",
    "# Se añaden todos los valores y el valor de bias a los valores de test\n",
    "X_test_all = np.hstack((X[Test_Rows:],Test_data[:,:].reshape(Test_Rows,len(Test_data[0]))))\n",
    "\n",
    "# Se vuelve a calcular Theta\n",
    "theta_all = lstsq(X_train_all, Train_result)[0]\n",
    "\n",
    "#Se calcula el MSE para los valores de entrenamiento\n",
    "MSE_Train_all_Result = MSE(Train_result,X_train_all,theta_all)\n",
    "\n",
    "#Se calcula el MSE para los valores de test\n",
    "MSE_Test_all_Result = MSE(Test_result,X_test_all,theta_all)\n",
    "\n",
    "print 'Q4.- El MSE de los valores de entreno con todos los datos es: ', MSE_Train_all_Result\n",
    "print 'Q4.- El MSE de los valores de test con todos los datos es: ', MSE_Test_all_Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ahora se debe volver a calcular el parametro R² para cuantificar el comportamiento del metodo utilizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4.- El valor de R² con el nuevo metodo es:  -2.25273434239\n"
     ]
    }
   ],
   "source": [
    "# Se vuelve a calcular el R² utilizando los valores obtenidos en Q3\n",
    "R2_all = 1- (MSE_Test_all_Result/R2_var)\n",
    "\n",
    "print 'Q4.- El valor de R² con el nuevo metodo es: ', R2_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar el funcionamiento, se debe volver a calcular todo, eliminando la columna con peor valor, tal y como hemos calculado en la pregunta Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4.- El MSE de los valores de entreno con todos los datos menos la peor columna es:  10.2162833878\n",
      "\n",
      "Q4.- El MSE de los valores de test con todos los datos menos la peor columna es:  50.4903768903\n",
      "\n",
      "Q4.- El valor de R² eliminando la peor columna:  0.458761268201\n",
      "\n",
      "Q4.- Como se puede ver ahora el coeficiente ha mejorado, pero como el valor es menor de 0,5, no deja de ser un detector trivial\n"
     ]
    }
   ],
   "source": [
    "# Se elimina la columna con el peor indice, utilizando el valor encontrado en Q3, con la premisa que el indice\n",
    "# obtenido se debe sumar 1 para tener en cuenta el valor de bias\n",
    "X_train_all = np.delete(X_train_all, Test_index_max + 1, 1 ) \n",
    "\n",
    "X_test_all = np.delete(X_test_all, Test_index_max + 1, 1 ) \n",
    "\n",
    "# Se vuelve a calcular Theta\n",
    "theta_all = lstsq(X_train_all, Train_result)[0]\n",
    "   \n",
    "#Se calcula el MSE para los valores de entrenamiento\n",
    "MSE_Train_all_Result = MSE(Train_result,X_train_all,theta_all)\n",
    "\n",
    "#Se calcula el MSE para los valores de test\n",
    "MSE_Test_all_Result = MSE(Test_result,X_test_all,theta_all)\n",
    "\n",
    "print 'Q4.- El MSE de los valores de entreno con todos los datos menos la peor columna es: ', MSE_Train_all_Result\n",
    "print '\\nQ4.- El MSE de los valores de test con todos los datos menos la peor columna es: ', MSE_Test_all_Result\n",
    "\n",
    "# Se vuelve a calcular el R² utilizando los valores obtenidos en Q3\n",
    "R2_all = 1- (MSE_Test_all_Result/R2_var)\n",
    "\n",
    "print '\\nQ4.- El valor de R² eliminando la peor columna: ', R2_all\n",
    "\n",
    "print \"\\nQ4.- Como se puede ver ahora el coeficiente ha mejorado, pero como el valor es menor de 0,5, no deja de ser un detector trivial\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Q5**) Ahora se va a añadir más capacidad al predictor utilizando el *polynomial basis expansion*:\n",
    "\n",
    "\n",
    "Y = Theta_0 + Theta_1\\*X + Theta_2\\*X²+ Theta_3\\*X³ + Theta_4\\*X⁴ + ...\n",
    "\n",
    "En este caso se va a realizar hasta el orden 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5.- Los valores MSE de los datos de entrenamiento para las distintas columnas son:\n",
      "\n",
      "Attribute \tMSE_X\t\tMSE_X²\t\tMSE_X³\t\tMSE_X⁴\n",
      "CRIM \t\t65.7733954044 \t65.6179891362 \t64.3715418216 \t62.2906443389 \t\n",
      "ZN \t\t62.1848641294 \t61.0582195947 \t60.9252498867 \t59.9434024859 \t\n",
      "INDUS \t\t60.2029462983 \t54.2413256422 \t50.0448910408 \t49.8250055753 \t\n",
      "CHAS \t\t69.2403754686 \t69.2403754686 \t69.2403754686 \t69.2403754686 \t\n",
      "NOX \t\t61.5452790564 \t61.2908893082 \t61.267381972 \t61.1421064783 \t\n",
      "RM \t\t15.9351479206 \t14.4470745011 \t13.80410477 \t13.3225563454 \t\n",
      "AGE \t\t61.4274959173 \t60.2653055691 \t60.2202779936 \t59.2542521663 \t\n",
      "DIS \t\t68.0006230798 \t67.3816469855 \t64.7275796527 \t63.5733465798 \t\n",
      "RAD \t\t69.1493593766 \t63.1900072693 \t62.8125724475 \t62.7858571995 \t\n",
      "TAX \t\t65.435881603 \t65.4290025794 \t64.5343503218 \t63.3427603004 \t\n",
      "PTRATIO \t59.7509725826 \t57.2025156241 \t56.5899275703 \t55.6050080423 \t\n",
      "B \t\t66.0407527683 \t65.9110101513 \t65.672066416 \t65.3583544279 \t\n",
      "LSTAT \t\t34.3807557759 \t23.4484611007 \t20.6440360455 \t19.7888740196 \t\n",
      "\n",
      "\n",
      "Q5.- Los valores MSE de los datos de test para las distintas columnas son:\n",
      "\n",
      "Attribute \tMSE_X\t\tMSE_X²\t\tMSE_X³\t\tMSE_X⁴\n",
      "CRIM \t\t873.516873624 \t125944.792024 \t4863293828.92 \t5.0071567634e+13 \t\n",
      "ZN \t\t91.9337946648 \t98.8542413116 \t101.379654549 \t103.841428452 \t\n",
      "INDUS \t\t74.746111966 \t73.2312062623 \t85.8416136881 \t87.5156077596 \t\n",
      "CHAS \t\t105.203523044 \t105.203523044 \t105.203523044 \t105.203523044 \t\n",
      "NOX \t\t80.1601262255 \t78.5684512371 \t80.6690311303 \t102.945221661 \t\n",
      "RM \t\t78.0556344253 \t67.5284566983 \t67.8211361362 \t80.0841904876 \t\n",
      "AGE \t\t88.9553607233 \t87.321472345 \t87.0031120957 \t87.7214722577 \t\n",
      "DIS \t\t97.4632421909 \t92.2374734397 \t116.541984629 \t116.318409852 \t\n",
      "RAD \t\t144.90523085 \t34320.4828112 \t520027.447859 \t720635.345207 \t\n",
      "TAX \t\t67.5174809817 \t66.0689675665 \t7106.94711976 \t228316.85572 \t\n",
      "PTRATIO \t72.5071633306 \t77.0494595103 \t76.697644264 \t68.096642948 \t\n",
      "B \t\t86.4495001439 \t87.0488216857 \t103.09535778 \t126.017334911 \t\n",
      "LSTAT \t\t43.3437235953 \t43.3092762424 \t42.4440172979 \t40.9973504779 \t\n",
      "\n",
      "\n",
      "Q5.- Los valores R² para las distintas columnas son:\n",
      "\n",
      "Attribute \tR²_X\t\tR²_X²\t\tR²_X³\t\tR²_X⁴\n",
      "CRIM \t\t-8.363788 \t-1349.083 \t-52132764.6168 \t-5.36749246777e+11 \t\n",
      "ZN \t\t0.014503 \t-0.059682 \t-0.086754 \t-0.113143 \t\n",
      "INDUS \t\t0.198748 \t0.214988 \t0.079809 \t0.061864 \t\n",
      "CHAS \t\t-0.127744 \t-0.127744 \t-0.127744 \t-0.127744 \t\n",
      "NOX \t\t0.140712 \t0.157774 \t0.135257 \t-0.103536 \t\n",
      "RM \t\t0.163272 \t0.276119 \t0.272982 \t0.141526 \t\n",
      "AGE \t\t0.04643 \t0.063945 \t0.067358 \t0.059657 \t\n",
      "DIS \t\t-0.044771 \t0.011247 \t-0.249288 \t-0.246892 \t\n",
      "RAD \t\t-0.553332 \t-366.903267 \t-5573.507732 \t-7723.952443 \t\n",
      "TAX \t\t0.276237 \t0.291764 \t-75.183924 \t-2446.474807 \t\n",
      "PTRATIO \t0.222749 \t0.174057 \t0.177829 \t0.270028 \t\n",
      "B \t\t0.073292 \t0.066868 \t-0.105145 \t-0.350861 \t\n",
      "LSTAT \t\t0.535371 \t0.53574 \t0.545015 \t0.560523 \t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para poder imprimir correctamente los resultados, se va a crear un vector con los nombres de las \n",
    "# distintas columnas\n",
    "\n",
    "Array_names = [ \"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"]\n",
    "\n",
    "# Creamos unas variables para guardar los datos \n",
    "MSE_Train_Q5 = []\n",
    "MSE_Test_Q5 = []\n",
    "R2_Q5 = []\n",
    "\n",
    "# Se crea el bucle anidado para calcular los MSE\n",
    "for i in range(0,len(data[0])-1):\n",
    "    # Se crea el segundo bucle para calcular los datos de cada valor\n",
    "    \n",
    "    # Variables para guardar los datos obtenidos\n",
    "    MSE_Train_Q5_Row = []\n",
    "    MSE_Test_Q5_Row = []\n",
    "    R2_Q5_Row = []\n",
    "    \n",
    "    # Se incializan las variables\n",
    "    X_train_Q5 = X[:Train_Rows]\n",
    "    X_test_Q5 = X[Test_Rows:]\n",
    "    \n",
    "    for j in range(1,5):\n",
    "        # Se añade la columna a los datos de entreno\n",
    "        X_train_Q5 = np.hstack((X_train_Q5,(Train_data[:,i].reshape(Train_Rows,1))**j))\n",
    "\n",
    "        # Se añaden la columna a los datos de test\n",
    "        X_test_Q5 = np.hstack((X_test_Q5,(Test_data[:,i].reshape(Test_Rows,1))**j))\n",
    "\n",
    "        # Ahora se obtiene el valor de Theta con los valores de entrenamiento\n",
    "        theta_value_Q5 = lstsq(X_train_Q5,Train_result)[0]\n",
    "\n",
    "        #Se calcula el MSE para los valores de entrenamiento\n",
    "        MSE_Train_Q5_Row.append(MSE(Train_result,X_train_Q5,theta_value_Q5))\n",
    "\n",
    "        #Se calcula el MSE para los valores de test\n",
    "        MSE_Test_Q5_Row.append(MSE(Test_result,X_test_Q5,theta_value_Q5))\n",
    "        \n",
    "        #Se calcula el valor de R², utilizando los valores obtenidos en Q3\n",
    "        R2_Temp = 1 - (MSE_Test_Q5_Row[j-1]/R2_var)\n",
    "        R2_Q5_Row.append(R2_Temp)\n",
    "        \n",
    "    # Se añaden los valores calculados a las variables\n",
    "    MSE_Train_Q5.append(MSE_Train_Q5_Row)\n",
    "    MSE_Test_Q5.append(MSE_Test_Q5_Row)\n",
    "    R2_Q5.append(R2_Q5_Row)\n",
    "    \n",
    "# Se imprimen los valroes de una manera lo más limpia posible\n",
    "\n",
    "# MSE para los valores de entrenamiento\n",
    "print 'Q5.- Los valores MSE de los datos de entrenamiento para las distintas columnas son:\\n'\n",
    "print 'Attribute \\tMSE_X\\t\\tMSE_X²\\t\\tMSE_X³\\t\\tMSE_X⁴'\n",
    "# Se crea el bucle anidado para calcular los MSE\n",
    "for i in range(0,len(data[0])-1):\n",
    "    if i == 10:\n",
    "        print Array_names[i],'\\t',\n",
    "    else:\n",
    "        print Array_names[i],'\\t\\t',\n",
    "    \n",
    "    for j in range(0,4):\n",
    "        print MSE_Train_Q5[i][j],'\\t',\n",
    "    print ''\n",
    "    \n",
    "print'\\n'\n",
    "\n",
    "# MSE para los valores de test\n",
    "print 'Q5.- Los valores MSE de los datos de test para las distintas columnas son:\\n'\n",
    "print 'Attribute \\tMSE_X\\t\\tMSE_X²\\t\\tMSE_X³\\t\\tMSE_X⁴'\n",
    "# Se crea el bucle anidado para calcular los MSE\n",
    "for i in range(0,len(data[0])-1):\n",
    "    if i == 10:\n",
    "        print Array_names[i],'\\t',\n",
    "    else:\n",
    "        print Array_names[i],'\\t\\t',\n",
    "    \n",
    "    for j in range(0,4):\n",
    "        print MSE_Test_Q5[i][j],'\\t',\n",
    "    print ''\n",
    "    \n",
    "print'\\n'\n",
    "\n",
    "# R²\n",
    "print 'Q5.- Los valores R² para las distintas columnas son:\\n'\n",
    "print 'Attribute \\tR²_X\\t\\tR²_X²\\t\\tR²_X³\\t\\tR²_X⁴'\n",
    "# Se crea el bucle anidado para calcular los MSE\n",
    "for i in range(0,len(data[0])-1):\n",
    "    if i == 10:\n",
    "        print Array_names[i],'\\t',\n",
    "    else:\n",
    "        print Array_names[i],'\\t\\t',\n",
    "    \n",
    "    for j in range(0,4):\n",
    "        # Se ajusta la salida a 6 decimales, para poder printarlo bien\n",
    "        R2_temp = round(R2_Q5[i][j],6)\n",
    "        print R2_temp,'\\t',\n",
    "    print ''\n",
    "    \n",
    "print'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Q5.- Como se puede ver en los resultados, el calculo mejora en algunos puntos, como por ejemplo en la columna 12, donde teniamos el valor que mejor funcionaba en el ejercicio Q3, donde va de 0,53 a 0,56, aunque, por otro lado, en la peor columna, la 0, el valor empeora considerablemente. Asi, que yo creo que este metodo podría funcionar bien en algunos casos, pero tambien puede funcionar mucho peor para otros muchos, por ejemplo, en la columna RAD el error aumenta exponencialmente, y en la columna TAX pasa de estar dentro de los margenes a ir muy mal.\n"
     ]
    }
   ],
   "source": [
    "# Resultado de Q5\n",
    "print \"\\n\\nQ5.- Como se puede ver en los resultados, el calculo mejora en algunos puntos,\",\n",
    "print \"como por ejemplo en la columna 12, donde teniamos el valor que mejor funcionaba en el\",\n",
    "print \"ejercicio Q3, donde va de 0,53 a 0,56, aunque, por otro lado, en la peor columna, la 0, el valor\",\n",
    "print \"empeora considerablemente. Asi, que yo creo que este metodo podría funcionar bien en algunos casos,\",\n",
    "print \"pero tambien puede funcionar mucho peor para otros muchos, por ejemplo, en la columna RAD el error\",\n",
    "print \"aumenta exponencialmente, y en la columna TAX pasa de estar dentro de los margenes a ir muy mal.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- **Q6**) Se deben implementar dos funciones para implementar *The objective function **f** for \n",
    "Regularized Linear Regression* y la función derivada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Se crea una función para la función regularized linear regresion\n",
    "def RLR(theta, X, Y, Lambda):\n",
    "    \n",
    "    # La formula es f(theta) = (1/N)*norm(X*Theta-y)²+lambda*norm(Theta)\n",
    "    \n",
    "    # Primer termino:(1/N)*norm(X*Theta-y)²\n",
    "    temp = dot(X,theta) - Y\n",
    "    Term_1 = (dot(temp,temp.T))/len(Y)\n",
    "    \n",
    "    #Segunda parte lambda*norm(Theta)\n",
    "    Term_2 = Lambda*dot(theta,theta.T)\n",
    "    \n",
    "    # Se la suma de los dos terminos de la ecuación\n",
    "    return Term_1+Term_2\n",
    "\n",
    "# Se crea la función para la función derivada de regularized linear regresion\n",
    "def Dev_RLR(theta, X, Y, Lambda):\n",
    "    \n",
    "    # La formula es f'(theta) = (2/N)* X^T*(X*Theta - Y) + 2*Lambda*Theta\n",
    "    \n",
    "    # Primer termino: (2/N)* X^T*(X*Theta - Y)\n",
    "    Term_1_p = (2*dot(X.T,(dot(X,theta)-Y)))/len(Y)\n",
    "    \n",
    "    # Segundo termino: 2*Lambda*Theta\n",
    "    Term_2_p = 2*Lambda*theta\n",
    "    \n",
    "    #Se devuelve la suma de los dos terminos\n",
    "    return Term_1_p + Term_2_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de probar todo, se debe verificar que funciona correctemante, por ello se verifican las pruebas que se proponen en el ejercicio siguiente:\n",
    "\n",
    " >   *f*(data_train_with_bias, labels_train, theta_all_zeros, Lambda=1) = 660.1083 \n",
    " \n",
    " \n",
    " >   *f'*(data_train_with_bias, labels_train, theta_all_zeros, Lambda=1) = [ -48.62, -20.40, -676.58, -422.27, -3.90, -24.70, -317.49, -3033.81, -206.06, -222.99, -15327.84, -857.69, -18476.12, -477.47]  \n",
    " \n",
    " \n",
    " >   *f*(data_train_with_bias, labels_train, theta_all_0.01, Lambda=1) = 328.66\n",
    " \n",
    " \n",
    " >   *f'*(data_train_with_bias, labels_train, theta_all_0.01, Lambda=1) = [ -31.98, -12.23, -485.03, -260.24, -2.55, -15.98, -212.42, -1923.15, -137.89, -146.50, -9899.61, -560.03, -12199.25, -285.86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f con theta = 0 :  660.108300395\n",
      "\n",
      "f' con theta = 0: \n",
      "[ -4.86150198e+01  -2.03998614e+01  -6.76578261e+02  -4.22271731e+02\n",
      "  -3.90434783e+00  -2.47029506e+01  -3.17485880e+02  -3.03381368e+03\n",
      "  -2.06060021e+02  -2.22990514e+02  -1.53278427e+04  -8.57690435e+02\n",
      "  -1.84761215e+04  -4.77468150e+02]\n",
      "\n",
      "f con theta = 0.01 :  328.66492035\n",
      "\n",
      "f' con theta = 0: \n",
      "[ -3.19848193e+01  -1.22303576e+01  -4.85026317e+02  -2.60237220e+02\n",
      "  -2.55443658e+00  -1.59756983e+01  -2.12422208e+02  -1.92315245e+03\n",
      "  -1.37894379e+02  -1.46504086e+02  -9.89960966e+03  -5.60027702e+02\n",
      "  -1.21992485e+04  -2.85863099e+02]\n",
      "\n",
      "\n",
      " Q6.- Con estos resultados obtenidos se puede confirma que las funciones son correctas.\n"
     ]
    }
   ],
   "source": [
    "# Se generan los valores de test:\n",
    "X_train_test = np.hstack((X[:Train_Rows],Train_data[:,:].reshape(Train_Rows,len(Train_data[0]))))\n",
    "theta_zero = np.zeros((X_train_test.shape[1],))\n",
    "theta_0_01 = np.zeros((len(X_train_test[0]),))\n",
    "theta_0_01.fill(0.01)\n",
    "\n",
    "# Primera prueba\n",
    "\n",
    "print 'f con theta = 0 : ', RLR(theta_zero,X_train_test, Train_result, 1)\n",
    "print '\\nf\\' con theta = 0: \\n', Dev_RLR(theta_zero,X_train_test, Train_result, 1)\n",
    "print '\\nf con theta = 0.01 : ', RLR(theta_0_01,X_train_test, Train_result, 1)\n",
    "print '\\nf\\' con theta = 0: \\n', Dev_RLR(theta_0_01,X_train_test, Train_result, 1)\n",
    "\n",
    "print '\\n\\n Q6.- Con estos resultados obtenidos se puede confirma que las funciones son correctas.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Q7**) El siguiente punto es implementar un entrenador para el modelo de *regularized linear regression* utilizando el *gradient descent*. Hay que seguir este pseudo código\n",
    "\n",
    "```\n",
    "0. Function Gradient_Descent\n",
    "1.   Initialize theta(0) at random\n",
    "2.   t=0, maxit=100, step=1e-6, loss=zeros(maxit)\n",
    "3.   loss(0) = f(theta)\n",
    "4.   do\n",
    "5.      t=t+1\n",
    "6.      theta(t) = theta(t-1) - step * f'(theta(t-1))\n",
    "7.      loss(t) = f(theta)\n",
    "8.   While t<maxit\n",
    "9.   return theta\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La primera Loss es  217326.651931\n",
      "La última Loss es  131.480829118\n",
      "\n",
      "Q7.- La Theta obtenida con el descenso de gradiente es: \n",
      "[ 0.00569316  0.97861943  0.04965476  0.0445124   0.74818226  0.09313422\n",
      "  0.19916925 -0.01549027  0.0197442   0.77074092 -0.07345776  0.70296116\n",
      "  0.07010206  0.31513156]\n",
      "\n",
      "Q7.- El MSE con el descenso de gradiente de los datos de entrenamiento es:  103.793445136\n",
      "\n",
      "Q7.- El MSE con el descenso de gradiente de los datos de test es  253.372432869\n",
      "\n",
      "Q7.- y el valor R² es:  -1.71606160787\n"
     ]
    }
   ],
   "source": [
    "# Función del gradient descent\n",
    "def Gra_Des(Lambda, step, iterations):\n",
    "    # Se incializa theta con un valor random\n",
    "    theta = []\n",
    "    theta.append(np.random.rand((len(X_train_test[0],))))\n",
    "    \n",
    "    # Se crea el vector de loss\n",
    "    loss = np.zeros(iterations)\n",
    "    \n",
    "    # Se inicializa el valor de control de bucle\n",
    "    t = 1\n",
    "    \n",
    "    # Se inicializa el valor de Loss para entrar en el primer bucle\n",
    "    loss[0] = RLR(theta[0],X_train_test, Train_result, Lambda)\n",
    "    \n",
    "    print 'La primera Loss es ', loss[0]\n",
    "    \n",
    "    # Se comienza el bucle\n",
    "    while (t < iterations):\n",
    "        # Se actualiza el valor de theta\n",
    "        theta.append(theta[t-1] - step * Dev_RLR(theta[t-1],X_train_test, Train_result, Lambda))\n",
    "        # Se actualiza el valor de loss\n",
    "        loss[t] = RLR(theta[t],X_train_test, Train_result, Lambda)\n",
    "        \n",
    "        # Se incrementa el valor de t\n",
    "        t = t+1\n",
    "        \n",
    "    print 'La última Loss es ', loss[iterations-1]\n",
    "    \n",
    "    # Devuelvo el último valor, como el más correcto\n",
    "    return theta[iterations-1]\n",
    "\n",
    "# Se llama a la función para obtener Theta\n",
    "Theta_Gra = Gra_Des(10, 1e-6,100)\n",
    "\n",
    "print '\\nQ7.- La Theta obtenida con el descenso de gradiente es: \\n', Theta_Gra\n",
    "\n",
    "# Ahora se comprueba como es de buena con su MSE y su parámetro R²\n",
    "\n",
    "# Se genera la matriz de datos de test para poder calcular el MSE\n",
    "X_Gra_test = np.hstack((X[Test_Rows:],Test_data[:,:].reshape(Test_Rows,len(Test_data[0]))))\n",
    "\n",
    "MSE_Gra_Des_Train = MSE(Train_result,X_train_test,Theta_Gra)\n",
    "\n",
    "#Se calcula el MSE para los valores de test\n",
    "MSE_Gra_Des_Test = MSE(Test_result,X_Gra_test,Theta_Gra)\n",
    "\n",
    "print '\\nQ7.- El MSE con el descenso de gradiente de los datos de entrenamiento es: ', MSE_Gra_Des_Train\n",
    "print '\\nQ7.- El MSE con el descenso de gradiente de los datos de test es ', MSE_Gra_Des_Test\n",
    "\n",
    "# Se vuelve a calcular el R² utilizando los valores obtenidos en Q3\n",
    "R2_Gra = 1- (MSE_Gra_Des_Test/R2_var)\n",
    "\n",
    "print '\\nQ7.- y el valor R² es: ', R2_Gra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se si he hecho bien la comprobación de los valores\n"
     ]
    }
   ],
   "source": [
    "print 'No se si he hecho bien la comprobación de los valores'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Q8**) Para la rutina de optimización se utilizará la función [*fmin_l_bfgs_b*](http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.optimize.fmin_l_bfgs_b.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
