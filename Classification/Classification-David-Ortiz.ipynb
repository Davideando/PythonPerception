{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Recognition Assignments 2: Classification\n",
    "\n",
    "Se preparan todas las librerías necesarias para ejecutar el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Se importa la librería numpy\n",
    "import numpy as np\n",
    "\n",
    "# Imports de la libreria scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "#Temporal\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "- **Q1**) Primero se tiene que implementar una función que haga la clasificación kNN para clasificar el dataset Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Se crean unas variables para guardar los datos de Iris y sus labels\n",
    "# Como el fichero tiene una línea al final, se pone el if x.strip(), ya que si esta vació, esta línea no la coge.\n",
    "data_Iris = np.array([map(float,x.split(',')[:-1]) for x in open('iris.data') if x.strip()])\n",
    "labels_Iris = np.array([x.split(',')[-1].strip() for x in open('iris.data') if x.strip()])\n",
    "\n",
    "# Se cargan las matrices para los indices de los grupos de test y los grupos de entrenamiento\n",
    "train_ = np.loadtxt('iris_idx_train.txt')\n",
    "test_ = np.loadtxt('iris_idx_test.txt')\n",
    "\n",
    "# Como son indices, se pasan a integers\n",
    "train_Index = train_.astype(int)\n",
    "test_Index = test_.astype(int)\n",
    "\n",
    "# Se crean las dos matrices a partir de los indices de entrenamiento\n",
    "train_dataIris = data_Iris[train_Index,:]\n",
    "train_labelsIris = labels_Iris[train_Index]\n",
    "\n",
    "# Se crean las dos matrices a partir de los indeces de test\n",
    "test_dataIris = data_Iris[test_Index,:]\n",
    "test_labelsIris = labels_Iris[test_Index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se tienen los datos, ya se puede pasar a realizar el algoritmo ***kNN*** que se implementará para un k desde 1 a 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k =  1 :    94.0 %.\n",
      "Accuracy for k =  2 :    92.0 %.\n",
      "Accuracy for k =  3 :    98.0 %.\n",
      "Accuracy for k =  4 :    94.0 %.\n",
      "Accuracy for k =  5 :    92.0 %.\n",
      "Accuracy for k =  6 :    90.0 %.\n",
      "Accuracy for k =  7 :    88.0 %.\n",
      "Accuracy for k =  8 :    82.0 %.\n",
      "Accuracy for k =  9 :    84.0 %.\n"
     ]
    }
   ],
   "source": [
    "# Definición de una función para calcular la exactitud de la detección\n",
    "def getAccuracy(calc_labels, results):\n",
    "    correct = 0\n",
    "    for i in range(len(results)):\n",
    "        if calc_labels[i][-1] == results[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(results))) * 100.0\n",
    "  \n",
    "# Definición del algoritmo kNN:\n",
    "def kNN_function(train_data, train_labels, test_data, test_labels):\n",
    "    for k in range(1,10):\n",
    "        # Primero se debe asignar la distancia entre los puntos de los dos test de datos\n",
    "        distance = cdist(train_data,test_data)\n",
    "        # Ahora se tiene que encontrar los valores más cercanos\n",
    "        minimum_dist = np.argsort(distance.T,1)[:,1:k+1]\n",
    "        # Con las etiquetas ordenadas, ahora se debe actualizar las etiquetas\n",
    "        minimum_labels = train_labels[minimum_dist]\n",
    "        #print minimum_labels\n",
    "        #print test_labels\n",
    "        #Por ultimo se debe adquirir la accuraccy\n",
    "        Acc_Value = getAccuracy(minimum_labels,test_labels)\n",
    "        #Acc_Value = getAccuracy(train_data,minimum_labels)\n",
    "        print 'Accuracy for k = ', k, ':   ',Acc_Value,'%.'\n",
    "        #acc = accuracy_score(test_labels, [Counter(x).most_common()[0][0] for x in minimum_labels] )\n",
    "        #print 'Accuracy ',k,':', acc\n",
    "        \n",
    "# We call the function with the train and test splits\n",
    "\n",
    "kNN_function(train_dataIris, train_labelsIris, test_dataIris, test_labelsIris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión no es tan buena como con las funciones kNN del módulo *sklearn.neighbors*, pero es bastante buena. El siguiente paso es hacer lo mismo con los valores de *3DClothing dataset*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pendiente de hacer lo del 3DClothing"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
